# üïµÔ∏è‚Äç‚ôÄÔ∏è Detector de Fake News - NLP

Bem-vindo ao reposit√≥rio do projeto **Detector de Fake News** focado em Processamento de Linguagem Natural (NLP). Este projeto tem como objetivo principal treinar, avaliar e interpretar modelos avan√ßados de NLP (como DistilBERT e DistilRoBERTa) para a classifica√ß√£o de not√≠cias, identificando se s√£o verdadeiras ou falsas (Fake News).

## üìå Resumo e Principais Funcionalidades

Este projeto cobre um ciclo completo (pipeline) de Ci√™ncia de Dados e Machine Learning para NLP:

1. **An√°lise Explorat√≥ria de Dados (EDA)**: Limpeza, processamento e visualiza√ß√£o das distribui√ß√µes de texto no conjunto de dados.
2. **Treinamento de Modelos**: Fine-tuning dos modelos pr√©-treinados [DistilBERT](https://huggingface.co/distilbert-base-uncased) e [DistilRoBERTa](https://huggingface.co/distilroberta-base) usando `PyTorch` e a biblioteca `transformers` da Hugging Face.
3. **Infer√™ncia**: Gera√ß√£o de previs√µes usando os modelos treinados para criar o arquivo de submiss√£o (e testar em novos dados).
4. **Interpretabilidade**: An√°lise de como o modelo toma suas decis√µes (import√¢ncia de tokens/palavras) para garantir a transpar√™ncia do modelo de Fake News.

## üìÇ Estrutura do Reposit√≥rio

```text
üì¶ fakenews_detector_nlp
 ‚î£ üìÇ datasets/              # Conjunto de dados (treino, teste e dados processados)
 ‚îÉ ‚î£ üìú ligia_dataset_processado.csv
 ‚îÉ ‚î£ üìú test.csv
 ‚îÉ ‚îó üìú train.csv
 ‚î£ üìÇ notebooks_colab/       # Notebooks principais focados no Google Colab
 ‚îÉ ‚î£ üìì EDA_Ligia_NLP.ipynb                     # An√°lise explorat√≥ria e limpeza
 ‚îÉ ‚î£ üìì Treinamento_DistilBERT_Ligia_NLP.ipynb  # Treinamento usando DistilBERT
 ‚îÉ ‚î£ üìì Treinamento_DistilRoBERTa_Ligia_NLP.ipynb # Treinamento usando DistilRoBERTa
 ‚îÉ ‚î£ üìì Inferencia_Ligia_NLP.ipynb              # Realiza as predi√ß√µes e cria a submiss√£o
 ‚îÉ ‚îó üìì Interpretabilidade_Ligia_NLP.ipynb      # Interpreta√ß√£o dos resultados (SHAP)
 ‚î£ üìÇ results/               # Modelos salvos p√≥s-treinamento
 ‚îÉ ‚î£ üì¶ best_distilbert_model.zip
 ‚îÉ ‚îó üì¶ best_distilroberta_model.zip
 ‚î£ üìú submission.csv         # Resultado final de predi√ß√µes
 ‚îó üìú README.md              # Documenta√ß√£o do projeto
```

## üì¶ Depend√™ncias Principais

Os notebooks foram estruturados para rodar **exclusivamente no Google Colab** (Recomendado pois √© necess√°rio GPU para rodar os modelos), mas caso deseje rodar localmente, o projeto depende das seguintes bibliotecas em Python:

- `pandas` e `numpy`: Manipula√ß√£o de dados.
- `matplotlib` e `seaborn`: Visualiza√ß√£o de dados.
- `torch` (PyTorch): Framework principal de Deep Learning.
- `transformers` (Hugging Face): Modelos de linguagem, Tokenizers e classes para fine-tuning.
- `scikit-learn`: M√©tricas e divis√µes de treino/teste.
- `gdown`: Download automatizado de arquivos via links do Google Drive.

## üöÄ Como Usar (Instru√ß√µes de Uso)

Voc√™ pode executar este projeto diretamente usando o **Google Colab** de maneira independente, devido √†s melhorias implementadas na forma de ingest√£o de dados. Siga os passos na ordem adequada do pipeline:

1. **An√°lise dos Dados**: Abra o notebook `EDA_Ligia_NLP.ipynb` para visualizar e entender o processamento de texto.
2. **Treinamento**: Escolha um dos notebooks de treinamento (`Treinamento_DistilBERT_Ligia_NLP.ipynb` ou `Treinamento_DistilRoBERTa_Ligia_NLP.ipynb`). O treinamento deve preferencialmente ser executado em ambiente com **GPU** ativada (no Colab: `Ambiente de execu√ß√£o -> Alterar o tipo de ambiente de execu√ß√£o -> GPU`).
3. **Infer√™ncia**: Ap√≥s ter os modelos gerados/baixados, utilize o `Inferencia_Ligia_NLP.ipynb` para prever no conjunto `test.csv` e gerar seu arquivo `submission.csv`.
4. **Compreendendo o Modelo**: Para maior transpar√™ncia, utilize o `Interpretabilidade_Ligia_NLP.ipynb` para ler as atribui√ß√µes e pesos que a IA deu a determinadas partes da not√≠cia.

---

## ‚ú® Feature de Destaque: Carregamento Online Direto (Sem Google Drive local)

Uma das maiores facilidades inclu√≠das nesta vers√£o do projeto √© a **Feature de carregamento online**.

- **Como funciona antes:** Os notebooks foram estruturados de forma que exigem que o utilizador monte seu disco (Google Drive Pessoal, `drive.mount('/content/drive')`), para fazer o salvamento e uploud dos arquivos de CSV e Modelos.


- **O que foi adicionado:** A depend√™ncia de montagem de drive pessoal foi substitu√≠da pelo uso da biblioteca `gdown`, dando a op√ß√£o de baixar os arquivos automaticamente atrav√©s de links p√∫blicos integrados diretamente ao c√≥digo. (do pr√≥prio autor do projeto)


**Benef√≠cios:**

- **Zero Configura√ß√£o:** Reduz muito o trabalho manual. Basta apertar _"Run All"_ no Colab e o notebook puxar√° o Dataset inteiro da nuvem diretamente para a inst√¢ncia tempor√°ria do Google Colab.
- **N√£o gasta armazenamento pessoal:** O dataset n√£o precisa ocupar espa√ßo no seu Google Drive.
- **Portabilidade perfeita:** Outros cientistas de dados e avaliadores podem reproduzir seus testes e resultados com 1 clique.


> **Nota:** Nos notebooks de **EDA** e **Treinamento**, a montagem do Google Drive permanece obrigat√≥ria para o salvamento dos modelos e dataset processado.

